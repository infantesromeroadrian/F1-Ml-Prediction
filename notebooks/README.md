# F1 ML Notebooks

This directory contains Jupyter notebooks for F1 race prediction model development and analysis.

---

## ğŸ““ Notebooks

### 1. `explore_dataset.ipynb` - Exploratory Data Analysis
**Purpose:** Initial data exploration, feature engineering experimentation, and model prototyping

**Status:** âš ï¸ EXPLORATION ONLY - Not for production use

**What's Inside:**
- 139 cells of comprehensive EDA
- Multiple model experiments (RF, XGBoost, Ensembles)
- Hyperparameter tuning with GridSearch
- Feature engineering prototypes

**Models Trained:**
- Winner Classifier (ROC-AUC: 0.97)
- Position Regressor (RMSE: 4.3)
- Points Regressor (RMSE: 5.1)

**Issues:**
- No integrated data validation
- No cross-validation
- Timestamp-based model naming
- Missing feature importance analysis

**Use For:**
- Understanding data patterns
- Testing new feature ideas
- Quick experimentation

**DON'T Use For:**
- Production model training
- Performance benchmarks
- Deployment

---

### 2. `train_production_model.ipynb` - Production Model Training âœ¨ NEW
**Purpose:** Train production-ready models with best practices

**Status:** âœ… PRODUCTION READY

**Key Features:**
- âœ… Integrated data validation (`src/ml/validation.py`)
- âœ… Cross-validation for robust metrics
- âœ… Feature importance analysis (RF + SHAP)
- âœ… Semantic versioning (`v1.1.0`, `v1.2.0`, etc.)
- âœ… Comprehensive logging and metrics
- âœ… Reproducible training pipeline

**Workflow:**
```
1. Load Data
   â†“
2. Feature Engineering (using src/ml/features.py)
   â†“
3. ğŸ”’ DATA VALIDATION (CRITICAL - anti-leakage)
   â†“
4. Train/Test Split (Temporal: 2023/2024)
   â†“
5. Cross-Validation Training
   â†“
6. Feature Importance Analysis
   â†“
7. Evaluation & Model Saving
   â†“
8. Model Versioning (semantic versions)
```

**Target Metrics:**
- Position RMSE < 2.5 positions (current: 4.3)
- Winner ROC-AUC > 0.95 (current: 0.97 âœ…)
- Points RMSE < 4.0 points (current: 5.1)

**Use For:**
- Training production models
- Benchmarking improvements
- Model versioning
- Feature analysis

---

## ğŸš€ How to Use

### Option 1: Quick Start (Use Existing Models)
```bash
# Current models are in models/ (v1.0.0)
# They are validated (no data leakage) but have high RMSE
```

### Option 2: Re-train Models (Recommended)
```bash
# 1. Activate environment
source f1-venv/bin/activate  # Linux/Mac
# or
.\f1-venv\Scripts\Activate.ps1  # Windows

# 2. Open production training notebook
jupyter notebook notebooks/train_production_model.ipynb

# 3. Run all cells (Kernel > Restart & Run All)

# 4. Check output in models/v1.1.0/
ls -lah models/v1.1.0/
```

### Option 3: Experiment with New Features
```bash
# Use explore_dataset.ipynb for experimentation
# Then copy successful features to src/ml/features.py
# Then re-train with train_production_model.ipynb
```

---

## ğŸ“‚ Directory Structure

```
notebooks/
â”œâ”€â”€ README.md                        # This file
â”œâ”€â”€ explore_dataset.ipynb            # EDA & experimentation (3 MB)
â”œâ”€â”€ train_production_model.ipynb     # Production training (NEW)
â””â”€â”€ (future notebooks)
    â”œâ”€â”€ hyperparameter_tuning.ipynb  # Planned
    â”œâ”€â”€ feature_selection.ipynb      # Planned
    â””â”€â”€ model_comparison.ipynb       # Planned
```

---

## âš ï¸ Important Notes

### DO:
- âœ… Use `train_production_model.ipynb` for production models
- âœ… Run data validation before training
- âœ… Use cross-validation
- âœ… Document model versions
- âœ… Save feature importance
- âœ… Track metrics over time

### DON'T:
- âŒ Deploy models from `explore_dataset.ipynb` to production
- âŒ Skip data validation
- âŒ Use timestamp-based model naming
- âŒ Train without cross-validation
- âŒ Ignore feature importance

---

## ğŸ”§ Troubleshooting

### "ModuleNotFoundError: No module named 'src'"
```bash
# Make sure you're in the project root
cd /path/to/f1-race-replay

# Install in editable mode
pip install -e .
```

### "Data file not found"
```bash
# Run data collection first
python src/ml/collect_historical_data.py

# Or specify existing data path in notebook
DATA_PATH = Path("your/data/path.parquet")
```

### "Validation failed: Data leakage detected"
```python
# Check which features are forbidden
from src.ml.validation import FORBIDDEN_FEATURES_AT_PREDICTION
print(FORBIDDEN_FEATURES_AT_PREDICTION)

# Make sure you dropped targets before training
X = df.drop(columns=['winner', 'race_position', 'points', ...])
```

---

## ğŸ“Š Model Versioning

### Current Versions

| Version | Date | Position RMSE | Winner AUC | Status | Notes |
|---------|------|---------------|------------|--------|-------|
| v1.0.0 | 2024-12-25 | 4.30 | 0.97 | âš ï¸ High RMSE | From explore_dataset.ipynb |
| v1.1.0 | TBD | TBD | TBD | ğŸ”„ In Progress | From train_production_model.ipynb |

### Version Naming

```
models/
â”œâ”€â”€ v1.0.0/          # Initial production model
â”œâ”€â”€ v1.1.0/          # Improved features (target: RMSE < 2.5)
â”œâ”€â”€ v1.2.0/          # Hyperparameter tuning
â”œâ”€â”€ v2.0.0/          # Architecture change (e.g., neural nets)
â””â”€â”€ latest -> v1.1.0 # Symlink to current production
```

**Semantic Versioning:**
- **Major (v2.0.0):** Breaking changes (different features, architecture)
- **Minor (v1.1.0):** New features, improvements (backward compatible)
- **Patch (v1.0.1):** Bug fixes, small tweaks

---

## ğŸ“š Resources

### Documentation
- [Model Validation Report](../MODEL_VALIDATION_REPORT.md)
- [Code Review Phase 3](../CODE_REVIEW_PHASE3.md)
- [Phase 1 Complete](../PHASE1_COMPLETE.md)

### Code References
- Feature Engineering: `src/ml/features.py`
- Data Validation: `src/ml/validation.py`
- Data Collection: `src/ml/data_collection.py`
- Prediction Engine: `src/ml/prediction.py`

### External Resources
- [FastF1 Documentation](https://docs.fastf1.dev/)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [SHAP for Model Interpretability](https://shap.readthedocs.io/)

---

## ğŸ¯ Next Steps

1. **Run `train_production_model.ipynb`** to create v1.1.0
2. **Compare metrics** with v1.0.0 baseline
3. **Deploy v1.1.0** if metrics improve
4. **Iterate** on features/hyperparameters

---

**Last Updated:** 2025-12-30  
**Maintainer:** Adrian Infantes (infantesromeroadrian@gmail.com)
