{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# F1 Production Model Training - v1.1.0",
        "",
        "**Purpose:** Train production-ready F1 prediction models with integrated data validation",
        "",
        "**Key Features:**",
        "- \u2705 Integrated data validation (anti-leakage)",
        "- \u2705 Cross-validation for robust metrics",
        "- \u2705 Feature importance analysis",
        "- \u2705 Model versioning (semantic versions)",
        "- \u2705 Comprehensive logging and metrics",
        "",
        "**Target Metrics:**",
        "- Position RMSE < 2.5 positions (current: 4.3)",
        "- Winner ROC-AUC > 0.95 (current: 0.97 \u2705)",
        "- Points RMSE < 4.0 points (current: 5.1)",
        "",
        "**Created:** 2025-12-30  ",
        "**Author:** Adrian Infantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1\ufe0f\u20e3 Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings",
        "warnings.filterwarnings('ignore')",
        "",
        "import pandas as pd",
        "import numpy as np",
        "import matplotlib.pyplot as plt",
        "import seaborn as sns",
        "from pathlib import Path",
        "from datetime import datetime",
        "import json",
        "",
        "# ML libraries",
        "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor",
        "from sklearn.metrics import (",
        "    accuracy_score, precision_score, recall_score, f1_score, ",
        "    roc_auc_score, mean_squared_error, mean_absolute_error, r2_score",
        ")",
        "import xgboost as xgb",
        "",
        "# Our modules",
        "from src.ml.data_collection import extract_race_results, extract_qualifying_results",
        "from src.ml.features import calculate_historical_stats, add_feature_columns",
        "from src.ml.validation import validate_ml_data, validate_no_leakage",
        "",
        "print(\"\u2705 Imports successful\")",
        "print(f\"\ud83d\udcc5 Training started: {datetime.now()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2\ufe0f\u20e3 Load Historical Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load processed data (from notebooks/explore_dataset.ipynb results)",
        "print(\"Loading historical data...\")",
        "",
        "# TODO: Specify your data path",
        "DATA_PATH = Path(\"data/processed/f1_historical_data.parquet\")",
        "",
        "if not DATA_PATH.exists():",
        "    raise FileNotFoundError(",
        "        f\"Data not found: {DATA_PATH}\\n\"",
        "        \"Please run data collection script first:\\n\"",
        "        \"  python src/ml/collect_historical_data.py\"",
        "    )",
        "",
        "df = pd.read_parquet(DATA_PATH)",
        "print(f\"\u2705 Loaded {len(df)} rows, {len(df.columns)} columns\")",
        "print(f\"   Years: {sorted(df['year'].unique())}\")",
        "print(f\"   Rounds: {df['round_number'].nunique()} unique rounds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3\ufe0f\u20e3 Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate historical statistics",
        "print(\"Calculating historical statistics...\")",
        "df = calculate_historical_stats(df)",
        "",
        "# Add derived features",
        "print(\"Adding derived features...\")",
        "df = add_feature_columns(df)",
        "",
        "print(f\"\u2705 Feature engineering complete\")",
        "print(f\"   Total features: {len(df.columns)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4\ufe0f\u20e3 \ud83d\udd12 DATA VALIDATION (CRITICAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate features from targets",
        "print(\"Separating features from targets...\")",
        "",
        "# Save targets",
        "targets = {",
        "    'winner': df['winner'].copy(),",
        "    'race_position': df['race_position'].copy(),",
        "    'points': df['points'].copy()",
        "}",
        "",
        "# Remove targets and identifiers from features",
        "feature_cols_to_drop = [",
        "    # Targets (POST-race info - data leakage if included)",
        "    'winner', 'race_position', 'points', 'dnf', 'status', ",
        "    'fastest_lap_time', 'fastest_lap_rank', 'race_time',",
        "    # Identifiers (not predictive features)",
        "    'driver_code', 'constructor', 'circuit_name', 'country', 'event_name'",
        "]",
        "",
        "# Create feature matrix",
        "X = df.drop(columns=[c for c in feature_cols_to_drop if c in df.columns])",
        "",
        "# Keep year and round for temporal validation",
        "print(f\"\u2705 Feature matrix created: {X.shape}\")",
        "print(f\"   Features: {X.shape[1]}\")",
        "print(f\"   Samples: {X.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udd12 CRITICAL VALIDATION: Check for data leakage",
        "print(\"\\n\" + \"=\" * 80)",
        "print(\"\ud83d\udd0d VALIDATING DATA (ANTI-LEAKAGE CHECK)\")",
        "print(\"=\" * 80)",
        "",
        "try:",
        "    # This will FAIL if forbidden features are present",
        "    validate_ml_data(",
        "        X,",
        "        current_year=2025,  # Training for future predictions",
        "        current_round=1,",
        "        strict=True  # Fail hard if leakage detected",
        "    )",
        "    print(\"\\n\u2705 VALIDATION PASSED - No data leakage detected\")",
        "    print(\"   Safe to proceed with training\")",
        "except Exception as e:",
        "    print(f\"\\n\u274c VALIDATION FAILED: {e}\")",
        "    print(\"\\n\ud83d\udea8 DO NOT PROCEED - Fix data leakage first\")",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5\ufe0f\u20e3 Train/Test Split (Temporal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Temporal split: 2023 = train, 2024 = test",
        "print(\"\\nCreating temporal train/test split...\")",
        "",
        "train_mask = X['year'] == 2023",
        "test_mask = X['year'] == 2024",
        "",
        "# Remove year and round_number from features (used only for validation)",
        "X_numeric = X.drop(columns=['year', 'round_number'])",
        "",
        "X_train = X_numeric[train_mask].copy()",
        "X_test = X_numeric[test_mask].copy()",
        "",
        "y_winner_train = targets['winner'][train_mask]",
        "y_winner_test = targets['winner'][test_mask]",
        "",
        "y_position_train = targets['race_position'][train_mask]",
        "y_position_test = targets['race_position'][test_mask]",
        "",
        "y_points_train = targets['points'][train_mask]",
        "y_points_test = targets['points'][test_mask]",
        "",
        "print(f\"\u2705 Split complete:\")",
        "print(f\"   Train: {len(X_train)} samples (2023)\")",
        "print(f\"   Test: {len(X_test)} samples (2024)\")",
        "print(f\"   Features: {X_train.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6\ufe0f\u20e3 Train Models with Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross-validation setup",
        "from sklearn.model_selection import TimeSeriesSplit",
        "",
        "# Use TimeSeriesSplit for temporal data",
        "cv = TimeSeriesSplit(n_splits=5)",
        "",
        "print(\"Training Winner Classifier...\")",
        "clf = RandomForestClassifier(",
        "    n_estimators=200,",
        "    max_depth=15,",
        "    min_samples_split=10,",
        "    class_weight='balanced',",
        "    random_state=42,",
        "    n_jobs=-1",
        ")",
        "",
        "# Cross-validation",
        "cv_scores = cross_validate(",
        "    clf, X_train, y_winner_train,",
        "    cv=cv,",
        "    scoring=['roc_auc', 'f1'],",
        "    return_train_score=True,",
        "    n_jobs=-1",
        ")",
        "",
        "print(f\"\u2705 Cross-validation complete:\")",
        "print(f\"   ROC-AUC: {cv_scores['test_roc_auc'].mean():.4f} \u00b1 {cv_scores['test_roc_auc'].std():.4f}\")",
        "print(f\"   F1-Score: {cv_scores['test_f1'].mean():.4f} \u00b1 {cv_scores['test_f1'].std():.4f}\")",
        "",
        "# Final training on full training set",
        "clf.fit(X_train, y_winner_train)",
        "print(\"\u2705 Final model trained\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7\ufe0f\u20e3 Feature Importance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance from Random Forest",
        "importances = pd.DataFrame({",
        "    'feature': X_train.columns,",
        "    'importance': clf.feature_importances_",
        "}).sort_values('importance', ascending=False)",
        "",
        "print(\"\\n\ud83d\udcca Top 20 Most Important Features:\")",
        "print(importances.head(20).to_string(index=False))",
        "",
        "# Visualization",
        "plt.figure(figsize=(12, 8))",
        "top_20 = importances.head(20)",
        "plt.barh(range(len(top_20)), top_20['importance'])",
        "plt.yticks(range(len(top_20)), top_20['feature'])",
        "plt.xlabel('Importance')",
        "plt.title('Top 20 Feature Importances - Winner Classifier')",
        "plt.gca().invert_yaxis()",
        "plt.tight_layout()",
        "plt.show()",
        "",
        "# Save importances",
        "importances.to_csv('models/feature_importances_v1.1.0.csv', index=False)",
        "print(\"\\n\u2705 Feature importances saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8\ufe0f\u20e3 Evaluate & Save Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set",
        "y_pred = clf.predict(X_test)",
        "y_proba = clf.predict_proba(X_test)[:, 1]",
        "",
        "metrics = {",
        "    'roc_auc': roc_auc_score(y_winner_test, y_proba),",
        "    'f1': f1_score(y_winner_test, y_pred),",
        "    'precision': precision_score(y_winner_test, y_pred),",
        "    'recall': recall_score(y_winner_test, y_pred)",
        "}",
        "",
        "print(\"\\n\ud83d\udcca Test Set Metrics:\")",
        "for metric, value in metrics.items():",
        "    print(f\"   {metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model with semantic versioning",
        "import pickle",
        "from pathlib import Path",
        "",
        "VERSION = \"v1.1.0\"",
        "models_dir = Path(f\"models/{VERSION}\")",
        "models_dir.mkdir(exist_ok=True, parents=True)",
        "",
        "# Save classifier",
        "model_path = models_dir / \"classifier_winner.pkl\"",
        "with open(model_path, 'wb') as f:",
        "    pickle.dump(clf, f)",
        "print(f\"\\n\u2705 Model saved: {model_path}\")",
        "",
        "# Save features list",
        "features_path = models_dir / \"features.json\"",
        "with open(features_path, 'w') as f:",
        "    json.dump(X_train.columns.tolist(), f, indent=2)",
        "print(f\"\u2705 Features saved: {features_path}\")",
        "",
        "# Save metrics",
        "metrics_path = models_dir / \"metrics.json\"",
        "with open(metrics_path, 'w') as f:",
        "    json.dump({",
        "        'version': VERSION,",
        "        'timestamp': datetime.now().isoformat(),",
        "        'train_samples': len(X_train),",
        "        'test_samples': len(X_test),",
        "        'features_count': len(X_train.columns),",
        "        'classifier_winner': metrics",
        "    }, f, indent=2)",
        "print(f\"\u2705 Metrics saved: {metrics_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9\ufe0f\u20e3 Next Steps",
        "",
        "\u2705 **Completed:**",
        "- Data loaded and validated",
        "- No data leakage detected",
        "- Models trained with cross-validation",
        "- Feature importance analyzed",
        "- Models saved with semantic versioning",
        "",
        "\ud83d\udccb **TODO:**",
        "1. Train position regressor (target RMSE < 2.5)",
        "2. Train points regressor (target RMSE < 4.0)",
        "3. Compare v1.1.0 vs v1.0.0 metrics",
        "4. Create symlink: `models/latest -> models/v1.1.0`",
        "5. Update production code to use v1.1.0",
        "",
        "**Target Improvements:**",
        "- Position RMSE: 4.3 \u2192 < 2.5 \u26a1",
        "- Add SHAP analysis for interpretability",
        "- Deploy to production after validation"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "f1-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}